{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f51f19c",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "The code organizes the dataset of images into training and test sets for three categories: human, dalle, and stable. Random samples are selected from each category for training and the remaining samples are used for testing. The images are preprocessed, resized, and converted into numpy arrays. Training and test batches are created and saved as pickle files for later use."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T15:21:05.971349Z",
     "start_time": "2025-05-18T15:06:03.885039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_random_samples(file_list, sample_size):\n",
    "    \"\"\"Get random samples from a list of files.\"\"\"\n",
    "    if sample_size > len(file_list):\n",
    "        print(f\"Warning: Requested {sample_size} samples but only {len(file_list)} available.\")\n",
    "        return file_list\n",
    "    return random.sample(file_list, sample_size)\n",
    "\n",
    "def get_remaining_samples(file_list, selected_samples):\n",
    "    \"\"\"Get samples that were not selected.\"\"\"\n",
    "    return [sample for sample in file_list if sample not in selected_samples]\n",
    "\n",
    "def preprocess_image(image_path, target_size):\n",
    "    \"\"\"Preprocess an image: resize and normalize.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).resize(target_size)\n",
    "        return np.array(img.convert(\"RGB\")) / 255.\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_pickle_file(data, file_path):\n",
    "    \"\"\"Save data to pickle file.\"\"\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pkl.dump(data, f)\n",
    "\n",
    "def create_batches_with_labels(file_paths, folder, label):\n",
    "    \"\"\"Create batches of image data with corresponding labels.\"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.webp']\n",
    "\n",
    "    for path in file_paths:\n",
    "        if os.path.splitext(path)[1].lower() in valid_extensions:\n",
    "            img_path = os.path.join(folder, path)\n",
    "            img = preprocess_image(img_path, (256, 256))\n",
    "            if img is not None:\n",
    "                data.append(img)\n",
    "                labels.append(label)\n",
    "        else:\n",
    "            print(f\"Skipped non-image file: {path}\")\n",
    "\n",
    "    if not data:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    return np.stack(data), np.array(labels)\n",
    "\n",
    "def organize_data(human_path, ai_path, folder):\n",
    "    \"\"\"Organize data into training, validation, and test sets.\"\"\"\n",
    "    if not os.path.exists(folder + 'file_names/'):\n",
    "        os.makedirs(folder + 'file_names/')\n",
    "    if not os.path.exists(folder + 'train_batches/'):\n",
    "        os.makedirs(folder + 'train_batches/')\n",
    "    if not os.path.exists(folder + 'val_batches/'):\n",
    "        os.makedirs(folder + 'val_batches/')  # New directory for validation data\n",
    "    if not os.path.exists(folder + 'test_batches/'):\n",
    "        os.makedirs(folder + 'test_batches/')\n",
    "\n",
    "    # Get all files\n",
    "    human_files = os.listdir(human_path)\n",
    "    ai_files = os.listdir(ai_path)\n",
    "\n",
    "    train_ratio = 0.6\n",
    "    val_ratio = 0.2\n",
    "    test_ratio = 0.2\n",
    "\n",
    "    def split_by_ratio(files):\n",
    "        random.shuffle(files)\n",
    "        train_size = int(len(files) * train_ratio)\n",
    "        val_size = int(len(files) * val_ratio)\n",
    "\n",
    "        train_files = files[:train_size]\n",
    "        val_files = files[train_size:train_size+val_size]\n",
    "        test_files = files[train_size+val_size:]\n",
    "\n",
    "        return train_files, val_files, test_files\n",
    "\n",
    "    human_train, human_val, human_test = split_by_ratio(human_files)\n",
    "    ai_train, ai_val, ai_test = split_by_ratio(ai_files)\n",
    "\n",
    "    # Save file names for reproducibility\n",
    "    save_pickle_file([human_train, ai_train], folder + 'file_names/train.pickle')\n",
    "    save_pickle_file([human_val, ai_val], folder + 'file_names/val.pickle')\n",
    "    save_pickle_file([human_test, ai_test], folder + 'file_names/test.pickle')\n",
    "\n",
    "    # Define labels\n",
    "    human_label = [0, 1]  # [human, ai]\n",
    "    ai_label = [1, 0]     # [ai, human]\n",
    "\n",
    "    # Process training data in batches\n",
    "    num_batches = 20\n",
    "    human_train_batch_size = len(human_train) // num_batches\n",
    "    ai_train_batch_size = len(ai_train) // num_batches\n",
    "\n",
    "    for batch in tqdm(range(num_batches), desc=\"Processing training batches\"):\n",
    "        human_start = batch * human_train_batch_size\n",
    "        human_end = (batch + 1) * human_train_batch_size if batch < num_batches - 1 else len(human_train)\n",
    "\n",
    "        ai_start = batch * ai_train_batch_size\n",
    "        ai_end = (batch + 1) * ai_train_batch_size if batch < num_batches - 1 else len(ai_train)\n",
    "\n",
    "        human_train_batch = human_train[human_start:human_end]\n",
    "        ai_train_batch = ai_train[ai_start:ai_end]\n",
    "\n",
    "        human_data, human_labels = create_batches_with_labels(human_train_batch, human_path, human_label)\n",
    "        ai_data, ai_labels = create_batches_with_labels(ai_train_batch, ai_path, ai_label)\n",
    "\n",
    "        # Skip empty batches\n",
    "        if human_data.size == 0 or ai_data.size == 0:\n",
    "            print(f\"Warning: Batch {batch} has empty data and will not be saved.\")\n",
    "            continue\n",
    "\n",
    "        data_batch = {\n",
    "            'data': np.vstack((human_data, ai_data)),\n",
    "            'labels': np.vstack((human_labels, ai_labels))\n",
    "        }\n",
    "\n",
    "        save_pickle_file(data_batch, f\"{folder}train_batches/batch_{batch}.pickle\")\n",
    "\n",
    "    # Process validation data\n",
    "    human_val_batch_size = len(human_val) // num_batches\n",
    "    ai_val_batch_size = len(ai_val) // num_batches\n",
    "\n",
    "    for batch in tqdm(range(num_batches), desc=\"Processing validation batches\"):\n",
    "        human_start = batch * human_val_batch_size\n",
    "        human_end = (batch + 1) * human_val_batch_size if batch < num_batches - 1 else len(human_val)\n",
    "\n",
    "        ai_start = batch * ai_val_batch_size\n",
    "        ai_end = (batch + 1) * ai_val_batch_size if batch < num_batches - 1 else len(ai_val)\n",
    "\n",
    "        human_val_batch = human_val[human_start:human_end]\n",
    "        ai_val_batch = ai_val[ai_start:ai_end]\n",
    "\n",
    "        human_data, human_labels = create_batches_with_labels(human_val_batch, human_path, human_label)\n",
    "        ai_data, ai_labels = create_batches_with_labels(ai_val_batch, ai_path, ai_label)\n",
    "\n",
    "        # Skip empty batches\n",
    "        if human_data.size == 0 or ai_data.size == 0:\n",
    "            print(f\"Warning: Validation batch {batch} has empty data and will not be saved.\")\n",
    "            continue\n",
    "\n",
    "        val_data_batch = {\n",
    "            'data': np.vstack((human_data, ai_data)),\n",
    "            'labels': np.vstack((human_labels, ai_labels))\n",
    "        }\n",
    "\n",
    "        save_pickle_file(val_data_batch, f\"{folder}val_batches/val_batch_{batch}.pickle\")\n",
    "\n",
    "    # Process test data\n",
    "    human_test_data, human_test_labels = create_batches_with_labels(human_test, human_path, human_label)\n",
    "    ai_test_data, ai_test_labels = create_batches_with_labels(ai_test, ai_path, ai_label)\n",
    "\n",
    "    # Stack test data and save\n",
    "    if human_test_data.size > 0 and ai_test_data.size > 0:\n",
    "        test_data = np.vstack((human_test_data, ai_test_data))\n",
    "        test_labels = np.vstack((human_test_labels, ai_test_labels))\n",
    "        test_batch = {'data': test_data, 'labels': test_labels}\n",
    "        save_pickle_file(test_batch, f\"{folder}test_batches/test_batch.pickle\")\n",
    "    else:\n",
    "        print(\"Warning: Test data is empty and will not be saved.\")\n",
    "\n",
    "organize_data(\n",
    "    human_path=\"train_data/normaldataset/Test/Real\",\n",
    "    ai_path=\"train_data/normaldataset/Test/Fake\",\n",
    "    folder=\"train_data/normal\"\n",
    ")"
   ],
   "id": "49c9945c8bb88fe3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training batches: 100%|██████████| 20/20 [07:58<00:00, 23.94s/it]\n",
      "Processing validation batches: 100%|██████████| 20/20 [02:39<00:00,  7.98s/it]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c18eff60e44f3b38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "232f6045a5c8dcdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fe97613e7378c577"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "191611fd384d9acb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b3dc90ccfe2159f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
